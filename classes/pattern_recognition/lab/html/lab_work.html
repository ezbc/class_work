
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      --><title>Lab Work on 'Pancreatic tumor segmentation and detection of tumor cells migration based on white light and second harmonic generation microscopic images', Lab 16</title><meta name="generator" content="MATLAB 8.3"><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2014-12-11"><meta name="DC.source" content="lab_work.m"><style type="text/css">
html,body,div,span,applet,object,iframe,h1,h2,h3,h4,h5,h6,p,blockquote,pre,a,abbr,acronym,address,big,cite,code,del,dfn,em,font,img,ins,kbd,q,s,samp,small,strike,strong,sub,sup,tt,var,b,u,i,center,dl,dt,dd,ol,ul,li,fieldset,form,label,legend,table,caption,tbody,tfoot,thead,tr,th,td{margin:0;padding:0;border:0;outline:0;font-size:100%;vertical-align:baseline;background:transparent}body{line-height:1}ol,ul{list-style:none}blockquote,q{quotes:none}blockquote:before,blockquote:after,q:before,q:after{content:'';content:none}:focus{outine:0}ins{text-decoration:none}del{text-decoration:line-through}table{border-collapse:collapse;border-spacing:0}

html { min-height:100%; margin-bottom:1px; }
html body { height:100%; margin:0px; font-family:Arial, Helvetica, sans-serif; font-size:10px; color:#000; line-height:140%; background:#fff none; overflow-y:scroll; }
html body td { vertical-align:top; text-align:left; }

h1 { padding:0px; margin:0px 0px 25px; font-family:Arial, Helvetica, sans-serif; font-size:1.5em; color:#d55000; line-height:100%; font-weight:normal; }
h2 { padding:0px; margin:0px 0px 8px; font-family:Arial, Helvetica, sans-serif; font-size:1.2em; color:#000; font-weight:bold; line-height:140%; border-bottom:1px solid #d6d4d4; display:block; }
h3 { padding:0px; margin:0px 0px 5px; font-family:Arial, Helvetica, sans-serif; font-size:1.1em; color:#000; font-weight:bold; line-height:140%; }

a { color:#005fce; text-decoration:none; }
a:hover { color:#005fce; text-decoration:underline; }
a:visited { color:#004aa0; text-decoration:none; }

p { padding:0px; margin:0px 0px 20px; }
img { padding:0px; margin:0px 0px 20px; border:none; }
p img, pre img, tt img, li img, h1 img, h2 img { margin-bottom:0px; } 

ul { padding:0px; margin:0px 0px 20px 23px; list-style:square; }
ul li { padding:0px; margin:0px 0px 7px 0px; }
ul li ul { padding:5px 0px 0px; margin:0px 0px 7px 23px; }
ul li ol li { list-style:decimal; }
ol { padding:0px; margin:0px 0px 20px 0px; list-style:decimal; }
ol li { padding:0px; margin:0px 0px 7px 23px; list-style-type:decimal; }
ol li ol { padding:5px 0px 0px; margin:0px 0px 7px 0px; }
ol li ol li { list-style-type:lower-alpha; }
ol li ul { padding-top:7px; }
ol li ul li { list-style:square; }

.content { font-size:1.2em; line-height:140%; padding: 20px; }

pre, code { font-size:12px; }
tt { font-size: 1.2em; }
pre { margin:0px 0px 20px; }
pre.codeinput { padding:10px; border:1px solid #d3d3d3; background:#f7f7f7; }
pre.codeoutput { padding:10px 11px; margin:0px 0px 20px; color:#4c4c4c; }
pre.error { color:red; }

@media print { pre.codeinput, pre.codeoutput { word-wrap:break-word; width:100%; } }

span.keyword { color:#0000FF }
span.comment { color:#228B22 }
span.string { color:#A020F0 }
span.untermstring { color:#B20000 }
span.syscmd { color:#B28C00 }

.footer { width:auto; padding:10px 0px; margin:25px 0px 0px; border-top:1px dotted #878787; font-size:0.8em; line-height:140%; font-style:italic; color:#878787; text-align:left; float:none; }
.footer p { margin:0px; }
.footer a { color:#878787; }
.footer a:hover { color:#878787; text-decoration:underline; }
.footer a:visited { color:#878787; }

table th { padding:7px 5px; text-align:left; vertical-align:middle; border: 1px solid #d6d4d4; font-weight:bold; }
table td { padding:7px 5px; text-align:left; vertical-align:top; border:1px solid #d6d4d4; }





  </style></head><body><div class="content"><h1>Lab Work on 'Pancreatic tumor segmentation and detection of tumor cells migration based on white light and second harmonic generation microscopic images', Lab 16</h1><!--introduction--><p>Lab completed by: Elijah Bernstein-Cooper</p><!--/introduction--><h2>Contents</h2><div><ul><li><a href="#1">Warmp up 1)</a></li><li><a href="#2">Warmp up 2)</a></li><li><a href="#3">Warmp up 3)</a></li><li><a href="#4">4.2 Exercise</a></li><li><a href="#5">4.3 Exercise</a></li></ul></div><h2>Warmp up 1)<a name="1"></a></h2><p>Detect the edges of the rice</p><pre class="codeinput">clear;
close <span class="string">all</span>;

color_range = [100 200];
norm_color_range = color_range / 255;

a=imread(<span class="string">'cameraman.tif'</span>);
[m n]=size(a);
bw=im2bw(a,0.6);
<span class="comment">%imshow(bw)</span>
b=a.*uint8(bw);
<span class="comment">%imshow(b)</span>

<span class="comment">%imshow(a)</span>

<span class="comment">% Keep</span>
a(a &lt; color_range(1)) = 0; a(a &gt; color_range(2)) = 0;
<span class="comment">%imshow(a)</span>

a = imread(<span class="string">'rice.png'</span>);
bw=im2bw(a);
<span class="comment">%figure, imshow(bw)</span>

se = strel(<span class="string">'disk'</span>,1);
erode = imerode(bw,se);
<span class="comment">%figure, imshow(erode);</span>

bw_edges = bw;
bw_edges(imerode(bw,strel(<span class="string">'disk'</span>,1))) = 0; <span class="comment">%# mask all but the border</span>

imshow(bw_edges)
</pre><img vspace="5" hspace="5" src="lab_work_01.png" alt=""> <h2>Warmp up 2)<a name="2"></a></h2><p>Keep rice with areas between 200 and 300 pixels</p><pre class="codeinput">bw_area = xor(bwareaopen(bw, 200),  bwareaopen(bw,300));

figure, imshow(bw_area)
</pre><img vspace="5" hspace="5" src="lab_work_02.png" alt=""> <h2>Warmp up 3)<a name="3"></a></h2><p>Construct convex hull for rice with areas between 200 and 300 pixels</p><pre class="codeinput">CH = bwconvhull(bw_area);

figure, imshow(CH)
</pre><img vspace="5" hspace="5" src="lab_work_03.png" alt=""> <h2>4.2 Exercise<a name="4"></a></h2><p>Create feature set of hough transform of cancerous regions. The region size should be tuned to mask out the teardrop region which contains cancer. Region sizes chosen were 1000 and 500 pixels. The images represent the RGB SHG image with the convex hull of the mask of the cancerous region in black. The red bounding boxes are the regions of interest to compute the hough transform. I used the function hough_feature_generator provided by the authors to compute mask out the regions of cancer and perform a hough transform on the region. The features used to identify regions of cancer are the maximum value of the Hough matrix, the average of all elements of the Hough matrix, and the average of all nonzero elements of the Hough matrix</p><pre class="codeinput"><span class="comment">% load data</span>
data(1).HE_IMAGE=<span class="string">'TransformedTumour Pancreas 84-1.tif'</span>;
data(1).SHG_IMAGE=<span class="string">'pancreatic tumor 2000 - 84-1.tif'</span>;
data(2).HE_IMAGE=<span class="string">'TransformedTumour Pancreas 112-2.tif'</span>;
data(2).SHG_IMAGE=<span class="string">'pancreatic_tumor_112-2.tif'</span>;
data(2).region_size = (1000);
data(1).region_size = (500);

<span class="comment">% Perform masking and get properties of the hough transform</span>
<span class="keyword">for</span> i=1:length(data);
    [data(i).A,data(i).H_subimage,data(i).H_block]=hough_feature_generator(data(i).HE_IMAGE,data(i).SHG_IMAGE,data(i).region_size,false);

<span class="keyword">end</span>

disp(<span class="string">'Feature sets of 1st image'</span>)
disp(data(1).A)
disp(<span class="string">'Feature sets of 2nd image'</span>)
disp(data(2).A)

<span class="comment">%figure</span>
<span class="comment">%imshow(H_subimage)</span>
</pre><pre class="codeoutput">Warning: Directory already exists. 
Warning: Directory already exists. 
Feature sets of 1st image
  355.0000   56.5956  126.3734
  346.0000   57.1749  127.8603
  363.0000   62.6157  139.9041
  215.0000   34.4590   76.8729
  237.0000   40.1202   89.4316
  353.0000   56.7796  126.3502
  147.0000   22.4113   49.9801
  224.0000   37.3364   83.4538
  356.0000   58.1627  129.4989

Feature sets of 2nd image
  262.0000   47.6300  106.1604
  297.0000   49.0951  109.3515
  297.0000   53.3044  118.8763
  223.0000   37.9725   84.6042
  245.0000   43.9810   98.0400
  304.0000   52.9070  117.8417
  246.0000   44.2643   98.6689
  308.0000   49.8774  111.0938
  304.0000   55.1628  123.0142

</pre><img vspace="5" hspace="5" src="lab_work_04.png" alt=""> <img vspace="5" hspace="5" src="lab_work_05.png" alt=""> <h2>4.3 Exercise<a name="5"></a></h2><p>Correct classification was typically around 80\% for 30 hidden layers when using random initialized weight guesses. When the seed number was set to the example in the lab the correct classification rose to 90\%. Perhaps some discussion in the lab on how to best choose initial guesses for weights of the hidden layers in the neural network would help the user understand this difference.</p><p>The plot represents the rate of true positives over false positives. A steeper curve is ideal, where there are many true positives and few false positives.</p><pre class="codeinput"><span class="comment">% Create hidden layers of neural net</span>
net = patternnet(10);
<span class="comment">%view(net)</span>

<span class="comment">% Load the precomputed data</span>
load(<span class="string">'A'</span>); load(<span class="string">'b'</span>);

x=A';
t=zeros(2,length(b));
<span class="keyword">for</span> i=1:length(b)
    <span class="keyword">if</span> b(i,1)==1
        t(1,i)=1;
        t(2,i)=0;
    <span class="keyword">else</span>
        t(1,i)=0;
        t(2,i)=1;
    <span class="keyword">end</span>
<span class="keyword">end</span>

<span class="comment">% Initialize number of patterns in neural net</span>
setdemorandstream(391418381);
net = patternnet(30);

[net,tr] = train(net,x,t);
<span class="comment">%nntraintool</span>

<span class="comment">%plotperform(tr)</span>

testX = x(:,tr.testInd);
testT = t(:,tr.testInd);

testY = net(testX);
testIndices = vec2ind(testY);

plotconfusion(testT,testY)
[c,cm] = confusion(testT,testY);
fprintf(<span class="string">'Percentage Correct Classification: %f%%\n'</span>, 100*(1-c));
fprintf(<span class="string">'Percentage Incorrect Classification : %f%%\n'</span>, 100*c);
plotroc(testT,testY)
</pre><pre class="codeoutput">Percentage Correct Classification: 90.909091%
Percentage Incorrect Classification : 9.090909%
</pre><img vspace="5" hspace="5" src="lab_work_06.png" alt=""> <p class="footer"><br><a href="http://www.mathworks.com/products/matlab/">Published with MATLAB&reg; R2014a</a><br></p></div><!--
##### SOURCE BEGIN #####
%% Lab Work on 'Pancreatic tumor segmentation and detection of tumor cells migration based on white light and second harmonic generation microscopic images', Lab 16
% Lab completed by: Elijah Bernstein-Cooper

%% Warmp up 1)
% Detect the edges of the rice 

clear;
close all;

color_range = [100 200];
norm_color_range = color_range / 255;

a=imread('cameraman.tif');
[m n]=size(a);
bw=im2bw(a,0.6);
%imshow(bw)
b=a.*uint8(bw);
%imshow(b)

%imshow(a)

% Keep 
a(a < color_range(1)) = 0; a(a > color_range(2)) = 0;
%imshow(a)

a = imread('rice.png');
bw=im2bw(a);
%figure, imshow(bw)

se = strel('disk',1);
erode = imerode(bw,se);
%figure, imshow(erode);

bw_edges = bw;
bw_edges(imerode(bw,strel('disk',1))) = 0; %# mask all but the border

imshow(bw_edges)

%% Warmp up 2)
% Keep rice with areas between 200 and 300 pixels
bw_area = xor(bwareaopen(bw, 200),  bwareaopen(bw,300));

figure, imshow(bw_area)

%% Warmp up 3)
% Construct convex hull for rice with areas between 200 and 300 pixels
CH = bwconvhull(bw_area);

figure, imshow(CH)

%% 4.2 Exercise
% Create feature set of hough transform of cancerous regions. The region size
% should be tuned to mask out the teardrop region which contains cancer.
% Region sizes chosen were 1000 and 500 pixels. The images represent the RGB
% SHG image with the convex hull of the mask of the cancerous region in black.
% The red bounding boxes are the regions of interest to compute the hough
% transform. I used the function hough_feature_generator provided by the
% authors to compute mask out the regions of cancer and perform a hough
% transform on the region. The features used to identify regions of cancer are
% the maximum value of the Hough matrix, the average of all elements of the
% Hough matrix, and the average of all nonzero elements of the Hough matrix

% load data
data(1).HE_IMAGE='TransformedTumour Pancreas 84-1.tif';
data(1).SHG_IMAGE='pancreatic tumor 2000 - 84-1.tif';
data(2).HE_IMAGE='TransformedTumour Pancreas 112-2.tif';
data(2).SHG_IMAGE='pancreatic_tumor_112-2.tif';
data(2).region_size = (1000);
data(1).region_size = (500);

% Perform masking and get properties of the hough transform
for i=1:length(data);
    [data(i).A,data(i).H_subimage,data(i).H_block]=hough_feature_generator(data(i).HE_IMAGE,data(i).SHG_IMAGE,data(i).region_size,false);

end

disp('Feature sets of 1st image')
disp(data(1).A)
disp('Feature sets of 2nd image')
disp(data(2).A)

%figure
%imshow(H_subimage)


%% 4.3 Exercise
% Correct classification was typically around 80\% for 30 hidden layers when
% using random initialized weight guesses. When the seed number was set to the
% example in the lab the correct classification rose to 90\%. Perhaps some
% discussion in the lab on how to best choose initial guesses for weights of
% the hidden layers in the neural network would help the user understand this
% difference.
%
% The plot represents the rate of true positives over false positives. A
% steeper curve is ideal, where there are many true positives and few false
% positives.


% Create hidden layers of neural net
net = patternnet(10);
%view(net)

% Load the precomputed data
load('A'); load('b');

x=A';
t=zeros(2,length(b));
for i=1:length(b)
    if b(i,1)==1
        t(1,i)=1;
        t(2,i)=0;
    else
        t(1,i)=0;
        t(2,i)=1;
    end
end

% Initialize number of patterns in neural net
setdemorandstream(391418381);
net = patternnet(30);

[net,tr] = train(net,x,t);
%nntraintool

%plotperform(tr)

testX = x(:,tr.testInd);
testT = t(:,tr.testInd);

testY = net(testX);
testIndices = vec2ind(testY);

plotconfusion(testT,testY)
[c,cm] = confusion(testT,testY);
fprintf('Percentage Correct Classification: %f%%\n', 100*(1-c));
fprintf('Percentage Incorrect Classification : %f%%\n', 100*c);
plotroc(testT,testY)








##### SOURCE END #####
--></body></html>