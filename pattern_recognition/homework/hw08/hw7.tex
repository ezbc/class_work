%-------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%-------------------------------------------------------------------------------

\documentclass{article}

% Packages
\input{my_packages.tex}

% formatting
\input{my_format.tex}

%-------------------------------------------------------------------------------
%	NAME AND CLASS SECTION
%-------------------------------------------------------------------------------

\newcommand{\hmwkTitle}{Homework 7} % Assignment title
\newcommand{\hmwkDueDate}{Friday, Nov 7} % Due date
\newcommand{\hmwkClass}{ECE 532} % Course/class
\newcommand{\hmwkClassTime}{11:00 am} % Class/lecture time
\newcommand{\hmwkClassInstructor}{Robert Nowak} % Teacher/lecturer
\newcommand{\hmwkAuthorName}{Elijah Bernstein-Cooper} % Your name

%-------------------------------------------------------------------------------
%	TITLE PAGE
%-------------------------------------------------------------------------------

\title{\vspace{0in}
    \textmd{\textbf{\hmwkClass:\ \hmwkTitle}}\\
    \normalsize\vspace{0.1in}\small{Due\ on\ \hmwkDueDate}\\
    \vspace{0.1in}\large{\textit{\hmwkClassInstructor\ \hmwkClassTime}}
    \vspace{0.5in}}

\author{\textbf{Elijah Bernstein-Cooper}}
\date{\today} % Insert date here if you want it to appear below your name

%-------------------------------------------------------------------------------

\begin{document}

\maketitle
%\newpage

%===============================================================================
%-------------------------------------------------------------------------------
%	PROBLEM 1
%-------------------------------------------------------------------------------
\begin{homeworkProblem}

    We derived dual and primal least squares solutions to classify the training
    data. We set the regularization parameter $\lambda = 10^{-5}$. See
    Figure~\ref{fig:prob1} for the resulting prediction compared to the
    original training data. 50\% of the data was classified incorrectly by
    least squares. See the code at the end of the homework.
    
    \begin{figure}[!ht]
        \begin{centering}
        \includegraphics[scale=1.]{fig_prob1.png}

        \caption{\label{fig:prob1} The original data on the left, classified as
            negative (red) or positive (blue). The least squares dual solution
            is shown in the middle, and the least squares primal solution is
            shown on the right. We can see that least squares is an
            inappropriate classifier for this data.}
        \end{centering}

    \end{figure} 

\end{homeworkProblem}
\clearpage
%===============================================================================

%===============================================================================
%-------------------------------------------------------------------------------
%	PROBLEM 2 
%-------------------------------------------------------------------------------
\begin{homeworkProblem}
   
    We classified the training data with a Gaussian kernel, which is a much
    more appropriate classifier than least squares. See Figure~\ref{fig:prob2}
    for the results. The percent of mistakes made using the Gaussian kernel was
    1\%, 50 $\times$ fewer mistakes than least squares. We set the
    regularization parameter $\lambda = 10^{-5}$. See the code at the end of
    the homework. 

    \begin{figure}[!ht]
        
        \begin{centering}
        \includegraphics[scale=1.0]{fig_prob2.png}

        \caption{\label{fig:prob2} The original data on the left, classified as
        negative (red) or positive (blue). The Gaussian kernel classification
    is on the right.}
        \end{centering}

    \end{figure} 

\end{homeworkProblem}
%===============================================================================

%===============================================================================
%-------------------------------------------------------------------------------
%	PROBLEM 3
%-------------------------------------------------------------------------------
\begin{homeworkProblem}
   
    We classified the training data with a 2nd order polynomial kernel, which
    is a much more appropriate classifier than least squares, but does not
    perform as well in this case as the Gaussian kernel. See
    Figure~\ref{fig:prob3} for the results. The percent of mistakes made using
    the polynomial kernel was 4\%, 10 $\times$ fewer mistakes than least
    squares, and 4 $\times$ more mistakes than the Gaussian kernel.  We set the
    regularization parameter $\lambda = 10^{-5}$. See the code at the end of
    the homework. 

    \begin{figure}[!ht]
        
        \begin{centering}
        \includegraphics[scale=1.0]{fig_prob3.png}

        \caption{\label{fig:prob3} The original data on the left, classified as
        negative (red) or positive (blue). The polynomial kernel classification
    is on the right.}
        \end{centering}

    \end{figure} 

\end{homeworkProblem}
%===============================================================================

%===============================================================================
%-------------------------------------------------------------------------------
%	PROBLEM 4
%-------------------------------------------------------------------------------
\begin{homeworkProblem}
  
    We performed a simulation of generating datasets of sizes 10$\times$10,
    100$\times$100, 1000$\times$1000. For each dataset size, we ran 100
    iterations of regenerating the data, and classified the generated data with
    the least squares, Gaussian kernel, and polynomial kernels methods. We
    calculated the percent total of mistakes made by each of the three methods,
    see Table~\ref{table:prob4} for the results. See Figure~\ref{fig:prob4} for
    an example of classifications for a 1000$\times$1000 dataset. See the code
    at the end of the homework.

    \begin{table}[!ht]

        \caption{\label{table:prob4} Resulting \% total classification mistakes
        for different methods and dataset sizes.}

        \begin{center}
            \begin{tabular}{lccc}
                
                & 10$\times$10 & 100$\times$100 & 1000$\times$1000 \\
                \hline \hline
                Least Squares     & 33 & 45 & 48.4 \\
                Gaussian Kernel   & 0  & 1 & 1.3 \\
                Polynomial Kernel & 1  & 4 & 3.9 \\

            \end{tabular}
        \end{center}
    \end{table}

    \begin{figure}[!ht]
        
        \begin{centering}
        
        \includegraphics[width=\linewidth]{fig_prob4.png}

        \caption{\label{fig:prob4} Results from classifications of the training
        data. The Gaussian kernel outperforms the least squares and polynomial
    kernel classification.}
        \end{centering}

    \end{figure} 

\end{homeworkProblem}
%===============================================================================

\clearpage
{\huge Code:}

{\large \bf Problem 1} \\
\lstinputlisting{hw7_prob1.m} 
\hrule \hrule

{\large \bf Problem 2} \\
\lstinputlisting{hw7_prob2.m} 
\hrule \hrule

{\large \bf Problem 3} \\
\lstinputlisting{hw7_prob3.m} 
\hrule \hrule

{\large \bf Problem 4} \\
\lstinputlisting{hw7_prob4.m} 
\hrule \hrule

\end{document}

